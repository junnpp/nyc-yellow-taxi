{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc72c13-4208-4049-a9af-3b19c26500e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe313fd5-4cc8-4209-89f7-8518b013da44",
   "metadata": {},
   "source": [
    "## Retrieving the data links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6569e6b3-ab3b-47d6-a3b7-b9926a577136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a request to the website - NYC Taxi & Limousine Commission TLC Trip Record Data\n",
    "url = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "r = requests.get(url)\n",
    "html = r.content\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104c5095-e140-4f67-b497-8f0832678fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract all the yellow taxi link from the webpage\n",
    "taxi_links = list()\n",
    "for link in links:\n",
    "    cur_link = link.get(\"href\")\n",
    "    data_link = re.findall(r\".+\\.parquet$\", cur_link)\n",
    "    if data_link:\n",
    "        cur_link2 = data_link[0]\n",
    "        is_yellow = re.findall(r\".*yellow.*\", cur_link2)\n",
    "        if is_yellow:\n",
    "            taxi_links.append(is_yellow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcaea5d-73fb-4203-ab02-8ed5f70dc018",
   "metadata": {},
   "source": [
    "## Viewing sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afef8f3-5308-4cd2-b62f-16cb7f6388bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "df1 = pd.read_parquet(\"./temp-data/taxi-2021-1.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ed197-edfb-4202-8d21-8943d5563735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe51e99-3213-4514-a9b1-a1ecd66548a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35961c-7c35-4514-9587-b1c0f338424b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Analysis using DuckDB\n",
    "\n",
    "### References:\n",
    "1. [PySpark @ RealPython](https://realpython.com/pyspark-intro/)\n",
    "2. [NYC Data Dictionary](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "3. [DuckDB - Query Syntax](https://duckdb.org/docs/sql/functions/timestamp.html)\n",
    "\n",
    "- Questions:\n",
    "    - What is the yearly/daily/hourly taxi traffic for each taxi zone in NYC?\n",
    "    - When is a driver more likely to get higher amount of tip?\n",
    "    - When/where a driver is more likely to get a customer(s)?\n",
    "    - For each taxi zone, how far a taxi driver is likely to drive? Is there any particular zone with particularly higher overall trip distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b5c99-44ca-4162-9a89-1ed950974074",
   "metadata": {},
   "source": [
    "### Reading in Each Month's Data (parquet files)\n",
    "\n",
    "1. Thought about compressing parquet files, but [it is inefficient](https://stackoverflow.com/questions/60774906/how-to-write-a-parquet-bytes-object-as-zipfile-to-disk).\n",
    "2. Tried combining all of them into a single SQL database, but it takes up too much storage.\n",
    "3. Tried reading and analyzing monthly data individually from 2011 to 2022.\n",
    "   - Changed the scope to from 2016 to 2022 due to column specifiation (DOLocationID & PULocationID)\n",
    "4. Thought about using API, but it's much more time consuming (working with a generator with millions of rows).\n",
    "5. **Currently trying to work with `pandas` and `duckdb`**\n",
    "    - `dask` does not work when trying to read parquet files from the web due to \"encoding error.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4307d-a9d6-4e8e-8dcb-680584064f5c",
   "metadata": {},
   "source": [
    "## Preparing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58d687-06f9-4b95-b02c-a15ff77583be",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb3e225-c8f3-4e81-997e-9714216d9d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update taxi_links: only select data between 2016 and 2022\n",
    "taxi_links_11_22 = list()\n",
    "for link in taxi_links:\n",
    "    cur_year = link.split(\"_\")[-1].split(\"-\")[0]\n",
    "    if 2011 <= int(cur_year) and int(cur_year) <= 2022:\n",
    "        taxi_links_11_22.append(link)\n",
    "taxi_links_11_22[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1ce29-bd9b-4cea-9256-ae96b99a8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(taxi_links), \",\", len(taxi_links_11_22))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc099c-bc12-4a82-b2a5-b76fe6d829fd",
   "metadata": {},
   "source": [
    "### Efficiently Load Data from Large Parquet Files\n",
    "\n",
    "1. Load less data by specifying desired columns\n",
    "2. Change data type into more efficient formats\n",
    "3. Use `duckdb` to query each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed2cef-c9d2-4590-9733-6f5f6ce73a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"PULocationID\", \"total_amount\", \"tip_amount\", \"trip_distance\"]\n",
    "jan_2011 = pd.read_parquet(\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet\", columns = columns_to_use)\n",
    "jan_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3368b415-3c2d-4e0e-9755-06ddffe89a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e48b3-6bf5-4073-a750-e3bc19510106",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011[[\"PULocationID\", \"total_amount\", \"tip_amount\", \"trip_distance\"]] = jan_2011[[\"PULocationID\", \"total_amount\", \"tip_amount\", \"trip_distance\"]].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3cb92-1a62-4819-9194-54599f4d6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ae412-452e-45e5-8a71-30e365af9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54ad5b-c145-4a5f-888e-0c5e3f719dbf",
   "metadata": {},
   "source": [
    "## Understand the data\n",
    "\n",
    "In order to understand the data more in depth, it is crucial to know how they are recorded. First, make sure to read the data description from the [NYC TLC data dictionary](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "and study how [taximeter works](https://www.staxi.nl/en/how-taximeters-work/#:~:text=How%20a%20taximeter%20works,taxi%20travels%20a%20certain%20distance.). There are few irregular rows and deciding what to do with them heavily depends on these domain knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20846d55-bad9-4ea9-bb95-47d6ed649bf2",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "\n",
    "Filtered out the followings rows:\n",
    "\n",
    "1. Rides with `trip_distance` of 0.\n",
    "2. Rides with `trip_time` <= 1.\n",
    "3. Rides that would require the speed of more than 100 mph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413ce00-10fd-4fb8-8b2b-b5859293425d",
   "metadata": {},
   "source": [
    "Let's create a new column `trip_time` which indicates the total time spent per ride. Notice there are few rides with negative `trip_time` which does not make sense. Let's filter and take a look at those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd08ae-eca4-4f67-9677-176fee77a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011 = duckdb.query(\"\"\"\n",
    "    SELECT *, DATE_DIFF('minute', tpep_pickup_datetime, tpep_dropoff_datetime) AS trip_time\n",
    "    FROM jan_2011\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e1e16c-027d-40b0-a108-48b5e36049fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM jan_2011\n",
    "    WHERE trip_time < 0\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0537bf-65d7-4b3f-aedb-77c28d329c93",
   "metadata": {},
   "source": [
    "Notice nearly all of them are from `PULocatonID` of 264 which is unknown borough according to [NYC Taxi Zone Code](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1abbe1-7302-4dbc-9499-8b29db122fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT PULocationID, COUNT(*) AS cnt\n",
    "    FROM jan_2011\n",
    "    WHERE DATE_DIFF('minute', tpep_pickup_datetime, tpep_dropoff_datetime) < 0\n",
    "    GROUP BY PULocationID\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233f391-0468-4c71-9e81-2eeb3425004a",
   "metadata": {},
   "source": [
    "There is a single row whose `PULocationID` is not 264 (Unknown location doe) and has a negative `trip_time`. Notice its `trip_distance` is also 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ee41b-368b-48b2-b6c5-690c8e083088",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM jan_2011\n",
    "    WHERE DATE_DIFF('minute', tpep_pickup_datetime, tpep_dropoff_datetime) < 0 AND PULocationID = 145.0\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae07e0-8af6-4437-b061-11015d372c3c",
   "metadata": {},
   "source": [
    "Let's see how many rows are of `trip_distance` 0. There are quite a few of them (n=76093). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1246ce-b929-45a6-9c1d-4d1107f1624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT *, DATE_DIFF('minute', tpep_pickup_datetime, tpep_dropoff_datetime) AS trip_time\n",
    "    FROM jan_2011\n",
    "    WHERE trip_distance = 0\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b3bf51-b131-4fc3-9f31-094c630425ea",
   "metadata": {},
   "source": [
    "What are the `trip_time` of those trips whose `trip_distance` is 0?\n",
    "\n",
    "- Notice many for them have `trip_time` of 0, 1, or negative values. Let's filter those rows out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13feb0-42d7-4e7c-8784-163273c8d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT trip_time, COUNT(*) AS cnt\n",
    "    FROM\n",
    "        (SELECT *, DATE_DIFF('minute', tpep_pickup_datetime, tpep_dropoff_datetime) AS trip_time\n",
    "        FROM jan_2011\n",
    "        WHERE trip_distance = 0) AS t1\n",
    "    GROUP BY trip_time\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68afb459-d1ad-4ad0-97d6-b3dc320f640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011 = duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM jan_2011\n",
    "    WHERE trip_distance != 0\n",
    "\"\"\").df()\n",
    "jan_2011.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6251d32-4c99-4dfb-8763-acf7b029e661",
   "metadata": {},
   "source": [
    "Rides with `trip_time` less than 0, 0, or 1 does not make any sense. Let's filter those rides out too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d253869-c743-4325-af8d-9502ab69952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM jan_2011\n",
    "    WHERE trip_time <= 0\n",
    "\"\"\").df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10f0ca-0bf8-4181-85ba-2f53e52cde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011 = duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM jan_2011\n",
    "    WHERE trip_time > 0\n",
    "\"\"\").df()\n",
    "\n",
    "jan_2011.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363203f2-c740-44db-9999-d40bed59f3c9",
   "metadata": {},
   "source": [
    "Few rows have really short `trip_time` but long `trip_distance`. Let's filter those rows out too.\n",
    "\n",
    "1. Convert `trip_time` to hour. [(Do the conversion first)](https://stackoverflow.com/questions/34504497/division-not-giving-my-answer-in-postgresql).\n",
    "2. Calculate the `avg_mph` column (the average speed of each ride).\n",
    "3. Filter out rows with `avg_mph` greater than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad241c22-7938-4d11-b7ba-df203555a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            *,\n",
    "            ROUND(CAST(trip_time AS decimal) / 60, 2) AS trip_time_hour,\n",
    "            trip_distance / trip_time_hour AS avg_mph\n",
    "        FROM jan_2011) AS t1\n",
    "    WHERE avg_mph >= 100\n",
    "    ORDER BY avg_mph \n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc2ba8-3808-466a-b10e-746fcb876349",
   "metadata": {},
   "source": [
    "Let's also filter out rides with extremely slow speed (less than 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67203317-142c-42c5-b95e-ccb3e9d4c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            *,\n",
    "            ROUND(CAST(trip_time AS decimal) / 60, 2) AS trip_time_hour,\n",
    "            trip_distance / trip_time_hour AS avg_mph\n",
    "        FROM jan_2011) AS t1\n",
    "    WHERE avg_mph < 1\n",
    "    ORDER BY avg_mph \n",
    "\"\"\").df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12548536-02ad-431e-9e03-37b2b4fd309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011 = duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            *,\n",
    "            ROUND(CAST(trip_time AS decimal) / 60, 2) AS trip_time_hour,\n",
    "            trip_distance / trip_time_hour AS avg_mph\n",
    "        FROM jan_2011) AS t1\n",
    "    WHERE avg_mph > 1 AND avg_mph < 100\n",
    "    ORDER BY tpep_pickup_datetime\n",
    "\"\"\").df()\n",
    "\n",
    "jan_2011.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1635ad-c52c-4484-a339-245fa0999514",
   "metadata": {},
   "source": [
    "### Create new columns\n",
    "    1. split pick up datetime into year, month, day, and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418276b7-8707-4f97-b8ab-c74c00637462",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011_v2 = duckdb.query(\"\"\"\n",
    "    SELECT *, DATE_TRUNC('hour', tpep_pickup_datetime) AS PUDate\n",
    "    FROM jan_2011\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c7619-e72f-48af-8e64-75d671fb373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type into more efficient ones for newly created columns\n",
    "jan_2011_v2[[\"trip_time\"]] = jan_2011_v2[[\"trip_time\"]].apply(pd.to_numeric, downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8ca91-9627-4a1c-80fd-d1d0672ba855",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b1bff-227a-4157-ab97-9f3378470a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unused columns\n",
    "jan_2011_v3 = duckdb.query(\"\"\"\n",
    "    SELECT PUDate, PULocationID, total_amount, tip_amount, trip_time, trip_distance\n",
    "    FROM jan_2011_v2\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff082d1c-2afc-4a33-b9d2-382aa2e8dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011_v3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d351507-f714-4133-be19-3d3f47f16e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011_v3.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74404243-1e63-48a4-93f1-84585fbeccfc",
   "metadata": {},
   "source": [
    "## Trend\n",
    "\n",
    "For NYC TLC (New York City Taxi and Limousine Commission), it would be important to know the overall traffic trend of yellow taxi by several time periods: hourly, daily, monhtly, and yearly.\n",
    "Let's analyze the overall traffic, total fare amount, and tip amount for each time period using previously created columns: `pickup_year`, `pickup_month`, `pickup_wday`, `pickup_hour`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39264136-cfc2-43b8-89b3-31f5870532bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2011_v4 = duckdb.query(\"\"\"\n",
    "    SELECT\n",
    "        PUDate, PULocationID,\n",
    "        COUNT(*) AS total_rides,\n",
    "        AVG(total_amount) AS avg_total_fare,\n",
    "        AVG(tip_amount) AS avg_tip,\n",
    "        AVG(trip_time) AS avg_trip_time,\n",
    "        AVG(trip_distance) AS avg_trip_distance\n",
    "    FROM jan_2011_v3\n",
    "    GROUP BY PUDate, PULocationID\n",
    "    ORDER BY PULocationID ASC, PUDate ASC\n",
    "\"\"\").df()\n",
    "\n",
    "jan_2011_v4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420458a4-c820-40fd-87c5-e68ff04ee90b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spatial Data for Visualization\n",
    "\n",
    "Certain columns are numerically coded including `PULocationID` and `pickup_wday`. Let's use another dataframe that contain geospatial data\n",
    "and Tableau to convert those values properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab2c5609-858e-4a46-9079-cadec1a726e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.918 192536.086, 933091.011 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((1033269.244 172126.008, 103343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.770 256767.698, 1026495.593 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.467 203714.076, 992068.667 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.310 144283.336, 936046.565 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0         1    0.116357    0.000782           Newark Airport           1   \n",
       "1         2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2         3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3         4    0.043567    0.000112            Alphabet City           4   \n",
       "4         5    0.092146    0.000498            Arden Heights           5   \n",
       "\n",
       "         borough                                           geometry  \n",
       "0            EWR  POLYGON ((933100.918 192536.086, 933091.011 19...  \n",
       "1         Queens  MULTIPOLYGON (((1033269.244 172126.008, 103343...  \n",
       "2          Bronx  POLYGON ((1026308.770 256767.698, 1026495.593 ...  \n",
       "3      Manhattan  POLYGON ((992073.467 203714.076, 992068.667 20...  \n",
       "4  Staten Island  POLYGON ((935843.310 144283.336, 936046.565 14...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "location_shape = gpd.read_file(\"./taxi_zones/taxi_zones.shp\")\n",
    "location_shape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4f8f8-9594-41b8-80de-f0768b11b103",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222697c-654e-4593-88c7-1adea8b2a2f4",
   "metadata": {},
   "source": [
    "## Iterating Processing Procedure for All Data from 2011 to 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eac37b-d6a8-4c07-9d5f-11a1a1ba521c",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19abfb9c-f7ba-4d9a-abb9-009ba3d25cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(link):\n",
    "    \n",
    "    columns_to_use = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"PULocationID\", \"total_amount\", \"tip_amount\", \"trip_distance\"]\n",
    "    \n",
    "    df = pd.read_parquet(link, columns = columns_to_use)\n",
    "    \n",
    "    df[[\"PULocationID\", \"total_amount\", \"tip_amount\", \"trip_distance\"]] = df[[\"PULocationID\", \"total_amount\", \"tip_amount\", \"trip_distance\"]].apply(pd.to_numeric, downcast='float')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e8a1a-2315-4490-ba9d-cac844d6d01e",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a8e9714-1ff2-4b71-bb48-c639c8d4ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # New column : trip_time\n",
    "    # Filter out rows with `trip_distance` = 0\n",
    "    # Filter out rows with `trip_time` <= 0\n",
    "    df1 = duckdb.query(\"\"\"\n",
    "        SELECT *, DATE_DIFF('minute', tpep_pickup_datetime, tpep_dropoff_datetime) AS trip_time\n",
    "        FROM df\n",
    "        WHERE trip_distance != 0 AND trip_time > 0\n",
    "    \"\"\").df()\n",
    "    \n",
    "    # Filter out rides with average mph > 100 or mph < 1\n",
    "    df2 = duckdb.query(\"\"\"\n",
    "        SELECT *\n",
    "        FROM\n",
    "            (SELECT\n",
    "                *,\n",
    "                ROUND(CAST(trip_time AS decimal) / 60, 2) AS trip_time_hour,\n",
    "                trip_distance / trip_time_hour AS avg_mph\n",
    "            FROM df1) AS t1\n",
    "        WHERE avg_mph > 1 AND avg_mph < 100\n",
    "        ORDER BY tpep_pickup_datetime\n",
    "    \"\"\").df()\n",
    "    \n",
    "    # New Columns : Convert datetime to date for group analysis\n",
    "    df3 = duckdb.query(\"\"\"\n",
    "        SELECT *, date_trunc('hour', tpep_pickup_datetime) as PUDate\n",
    "        FROM df2\n",
    "    \"\"\").df()\n",
    "\n",
    "    df3[[\"trip_time\"]] = df3[[\"trip_time\"]].apply(pd.to_numeric, downcast='float')\n",
    "    \n",
    "    # Drop unused columns\n",
    "    df4 = duckdb.query(\"\"\"\n",
    "        SELECT PUDate, PULocationID, total_amount, tip_amount, trip_time, trip_distance\n",
    "        FROM df3\n",
    "    \"\"\").df()\n",
    "    \n",
    "    return df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e390a-691f-46ce-bca3-60adbcd05c94",
   "metadata": {},
   "source": [
    "## Trend\n",
    "\n",
    "- Analysis Grouped by `LocationID` and `PUDate` (pickup date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da83a017-742a-4021-96b7-983b2e976434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend(df):\n",
    "    df1 = duckdb.query(\"\"\"\n",
    "        SELECT\n",
    "            PUDate, PULocationID,\n",
    "            COUNT(*) AS total_rides,\n",
    "            AVG(total_amount) AS avg_total_fare,\n",
    "            AVG(tip_amount) AS avg_tip,\n",
    "            AVG(trip_time) AS avg_trip_time,\n",
    "            AVG(trip_distance) AS avg_trip_distance\n",
    "        FROM df\n",
    "        GROUP BY PUDate, PULocationID\n",
    "        ORDER BY PULocationID ASC, PUDate ASC\n",
    "    \"\"\").df()\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12b732da-4476-4f5b-b7fb-c5ee7aef412e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-05.parquet']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first few rows of the links of the data\n",
    "taxi_links_11_22[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8c788e3-8a11-4426-9606-5a53de533d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 2011-12 Data Processed, Total Row:  104695\n",
      ">> 2011-11 Data Processed, Total Row:  206923\n",
      ">> 2011-10 Data Processed, Total Row:  315818\n",
      ">> 2011-09 Data Processed, Total Row:  427225\n",
      ">> 2011-08 Data Processed, Total Row:  534977\n",
      ">> 2011-07 Data Processed, Total Row:  644151\n",
      ">> 2011-06 Data Processed, Total Row:  750436\n",
      ">> 2011-05 Data Processed, Total Row:  859713\n",
      ">> 2011-04 Data Processed, Total Row:  962151\n",
      ">> 2011-03 Data Processed, Total Row:  1069789\n",
      ">> 2011-02 Data Processed, Total Row:  1166291\n",
      ">> 2011-01 Data Processed, Total Row:  1268030\n",
      ">> 2012-12 Data Processed, Total Row:  1365748\n",
      ">> 2012-11 Data Processed, Total Row:  1460889\n",
      ">> 2012-10 Data Processed, Total Row:  1558664\n",
      ">> 2012-09 Data Processed, Total Row:  1659004\n",
      ">> 2012-08 Data Processed, Total Row:  1764154\n",
      ">> 2012-07 Data Processed, Total Row:  1868176\n",
      ">> 2012-06 Data Processed, Total Row:  1970560\n",
      ">> 2012-05 Data Processed, Total Row:  2073919\n",
      ">> 2012-04 Data Processed, Total Row:  2172068\n",
      ">> 2012-03 Data Processed, Total Row:  2277313\n",
      ">> 2012-02 Data Processed, Total Row:  2373981\n",
      ">> 2012-01 Data Processed, Total Row:  2473277\n",
      ">> 2013-12 Data Processed, Total Row:  2568551\n",
      ">> 2013-11 Data Processed, Total Row:  2659589\n",
      ">> 2013-10 Data Processed, Total Row:  2753270\n",
      ">> 2013-09 Data Processed, Total Row:  2844833\n",
      ">> 2013-08 Data Processed, Total Row:  2936318\n",
      ">> 2013-07 Data Processed, Total Row:  3029916\n",
      ">> 2013-06 Data Processed, Total Row:  3121945\n",
      ">> 2013-05 Data Processed, Total Row:  3216099\n",
      ">> 2013-04 Data Processed, Total Row:  3306951\n",
      ">> 2013-03 Data Processed, Total Row:  3403063\n",
      ">> 2013-02 Data Processed, Total Row:  3488896\n",
      ">> 2013-01 Data Processed, Total Row:  3583434\n",
      ">> 2014-12 Data Processed, Total Row:  3679019\n",
      ">> 2014-11 Data Processed, Total Row:  3770974\n",
      ">> 2014-10 Data Processed, Total Row:  3866279\n",
      ">> 2014-09 Data Processed, Total Row:  3959385\n",
      ">> 2014-08 Data Processed, Total Row:  4056458\n",
      ">> 2014-07 Data Processed, Total Row:  4152803\n",
      ">> 2014-06 Data Processed, Total Row:  4247922\n",
      ">> 2014-05 Data Processed, Total Row:  4347045\n",
      ">> 2014-04 Data Processed, Total Row:  4441580\n",
      ">> 2014-03 Data Processed, Total Row:  4539948\n",
      ">> 2014-02 Data Processed, Total Row:  4628131\n",
      ">> 2014-01 Data Processed, Total Row:  4722867\n",
      ">> 2015-12 Data Processed, Total Row:  4816548\n",
      ">> 2015-11 Data Processed, Total Row:  4906125\n",
      ">> 2015-10 Data Processed, Total Row:  4999119\n",
      ">> 2015-09 Data Processed, Total Row:  5089900\n",
      ">> 2015-08 Data Processed, Total Row:  5183866\n",
      ">> 2015-07 Data Processed, Total Row:  5277609\n",
      ">> 2015-06 Data Processed, Total Row:  5369846\n",
      ">> 2015-05 Data Processed, Total Row:  5466654\n",
      ">> 2015-04 Data Processed, Total Row:  5558814\n",
      ">> 2015-03 Data Processed, Total Row:  5656047\n",
      ">> 2015-02 Data Processed, Total Row:  5743685\n",
      ">> 2015-01 Data Processed, Total Row:  5836027\n",
      ">> 2016-12 Data Processed, Total Row:  5926416\n",
      ">> 2016-11 Data Processed, Total Row:  6012704\n",
      ">> 2016-10 Data Processed, Total Row:  6103492\n",
      ">> 2016-09 Data Processed, Total Row:  6192245\n",
      ">> 2016-08 Data Processed, Total Row:  6283944\n",
      ">> 2016-07 Data Processed, Total Row:  6376800\n",
      ">> 2016-06 Data Processed, Total Row:  6467575\n",
      ">> 2016-05 Data Processed, Total Row:  6562273\n",
      ">> 2016-04 Data Processed, Total Row:  6653134\n",
      ">> 2016-03 Data Processed, Total Row:  6747103\n",
      ">> 2016-02 Data Processed, Total Row:  6834007\n",
      ">> 2016-01 Data Processed, Total Row:  6925476\n",
      ">> 2017-12 Data Processed, Total Row:  7013086\n",
      ">> 2017-11 Data Processed, Total Row:  7096388\n",
      ">> 2017-10 Data Processed, Total Row:  7182930\n",
      ">> 2017-09 Data Processed, Total Row:  7267033\n",
      ">> 2017-08 Data Processed, Total Row:  7353037\n",
      ">> 2017-07 Data Processed, Total Row:  7440234\n",
      ">> 2017-06 Data Processed, Total Row:  7526537\n",
      ">> 2017-05 Data Processed, Total Row:  7615267\n",
      ">> 2017-04 Data Processed, Total Row:  7701672\n",
      ">> 2017-03 Data Processed, Total Row:  7791670\n",
      ">> 2017-02 Data Processed, Total Row:  7870935\n",
      ">> 2017-01 Data Processed, Total Row:  7958361\n",
      ">> 2018-12 Data Processed, Total Row:  8060670\n",
      ">> 2018-11 Data Processed, Total Row:  8158455\n",
      ">> 2018-10 Data Processed, Total Row:  8258091\n",
      ">> 2018-09 Data Processed, Total Row:  8351903\n",
      ">> 2018-08 Data Processed, Total Row:  8446905\n",
      ">> 2018-07 Data Processed, Total Row:  8539794\n",
      ">> 2018-06 Data Processed, Total Row:  8633087\n",
      ">> 2018-05 Data Processed, Total Row:  8728899\n",
      ">> 2018-04 Data Processed, Total Row:  8819847\n",
      ">> 2018-03 Data Processed, Total Row:  8912673\n",
      ">> 2018-02 Data Processed, Total Row:  8991515\n",
      ">> 2018-01 Data Processed, Total Row:  9077690\n",
      ">> 2019-12 Data Processed, Total Row:  9174113\n",
      ">> 2019-11 Data Processed, Total Row:  9266350\n",
      ">> 2019-10 Data Processed, Total Row:  9362108\n",
      ">> 2019-09 Data Processed, Total Row:  9454601\n",
      ">> 2019-08 Data Processed, Total Row:  9549254\n",
      ">> 2019-07 Data Processed, Total Row:  9647051\n",
      ">> 2019-06 Data Processed, Total Row:  9745571\n",
      ">> 2019-05 Data Processed, Total Row:  9846533\n",
      ">> 2019-04 Data Processed, Total Row:  9946501\n",
      ">> 2019-03 Data Processed, Total Row:  10049767\n",
      ">> 2019-02 Data Processed, Total Row:  10143148\n",
      ">> 2019-01 Data Processed, Total Row:  10244084\n",
      ">> 2020-12 Data Processed, Total Row:  10323876\n",
      ">> 2020-11 Data Processed, Total Row:  10402602\n",
      ">> 2020-10 Data Processed, Total Row:  10485190\n",
      ">> 2020-09 Data Processed, Total Row:  10562888\n",
      ">> 2020-08 Data Processed, Total Row:  10641484\n",
      ">> 2020-07 Data Processed, Total Row:  10714505\n",
      ">> 2020-06 Data Processed, Total Row:  10778706\n",
      ">> 2020-05 Data Processed, Total Row:  10840003\n",
      ">> 2020-04 Data Processed, Total Row:  10884897\n",
      ">> 2020-03 Data Processed, Total Row:  10959877\n",
      ">> 2020-02 Data Processed, Total Row:  11047701\n",
      ">> 2020-01 Data Processed, Total Row:  11141725\n",
      ">> 2021-12 Data Processed, Total Row:  11213229\n",
      ">> 2021-11 Data Processed, Total Row:  11286968\n",
      ">> 2021-10 Data Processed, Total Row:  11364102\n",
      ">> 2021-09 Data Processed, Total Row:  11441075\n",
      ">> 2021-08 Data Processed, Total Row:  11521926\n",
      ">> 2021-07 Data Processed, Total Row:  11602652\n",
      ">> 2021-06 Data Processed, Total Row:  11681631\n",
      ">> 2021-05 Data Processed, Total Row:  11764334\n",
      ">> 2021-04 Data Processed, Total Row:  11847629\n",
      ">> 2021-03 Data Processed, Total Row:  11932377\n",
      ">> 2021-02 Data Processed, Total Row:  12003093\n",
      ">> 2021-01 Data Processed, Total Row:  12081381\n",
      ">> 2022-09 Data Processed, Total Row:  12149391\n",
      ">> 2022-08 Data Processed, Total Row:  12218795\n",
      ">> 2022-07 Data Processed, Total Row:  12288477\n",
      ">> 2022-06 Data Processed, Total Row:  12358808\n",
      ">> 2022-05 Data Processed, Total Row:  12429985\n",
      ">> 2022-04 Data Processed, Total Row:  12497813\n",
      ">> 2022-03 Data Processed, Total Row:  12566370\n",
      ">> 2022-02 Data Processed, Total Row:  12626876\n",
      ">> 2022-01 Data Processed, Total Row:  12689473\n"
     ]
    }
   ],
   "source": [
    "# specifying required columns for the data analysis\n",
    "data_list = list()\n",
    "total_row = 0\n",
    "for link in reversed(taxi_links_11_22):\n",
    "    cur_year = link.split(\"_\")[-1].split(\"-\")[0]\n",
    "    cur_month = link.split(\"-\")[-1].split(\".\")[0]\n",
    "    \n",
    "    # read raw data with columns specified\n",
    "    data = read_data(link)\n",
    "    \n",
    "    # clean data\n",
    "    cleaned_df = clean_data(data)\n",
    "    \n",
    "    # trend analysis per location_id\n",
    "    trend_df = trend(cleaned_df)\n",
    "    \n",
    "    data_list.append(trend_df)\n",
    "    \n",
    "    total_row += trend_df.shape[0]\n",
    "    \n",
    "    print(f\">> {cur_year}-{cur_month} Data Processed, Total Row: \", total_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6300e72-32f9-40e6-b024-fb3fb9eecfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily saving the current dataframe\n",
    "if not os.path.exists(os.path.join(\".\", \"data\")):\n",
    "    os.mkdir(os.path.join(\".\", \"data\"))\n",
    "temp_taxi_df = pd.concat(data_list, ignore_index=True)\n",
    "temp_taxi_df.to_csv(os.path.join(\".\", \"data\", \"temp_taxi.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0db63-b691-4705-875d-0eec2ba7a122",
   "metadata": {},
   "source": [
    "Notice there are few rows with a suspicious pick up date. Let's filter out those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09135d6d-e8e7-462a-a2a5-8d7c5e694345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUDate</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>total_rides</th>\n",
       "      <th>avg_total_fare</th>\n",
       "      <th>avg_tip</th>\n",
       "      <th>avg_trip_time</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-31 23:00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 01:00:00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.36</td>\n",
       "      <td>8.80</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 23:00:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-31 11:00:00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.27</td>\n",
       "      <td>8.21</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 01:00:00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>2008-12-31 23:00:00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>2009-01-01 00:00:00</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>2009-01-01 09:00:00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>2008-12-31 23:00:00</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>2009-01-01 06:00:00</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1613 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  PUDate  PULocationID  total_rides  avg_total_fare  avg_tip  \\\n",
       "0    2008-12-31 23:00:00          13.0            1            9.80     0.00   \n",
       "1    2009-01-01 01:00:00          41.0            1           54.36     8.80   \n",
       "2    2009-01-01 23:00:00          50.0            1           10.80     0.00   \n",
       "3    2008-12-31 11:00:00          70.0            1           49.27     8.21   \n",
       "4    2009-01-01 01:00:00          79.0            1           21.80     0.00   \n",
       "...                  ...           ...          ...             ...      ...   \n",
       "1608 2008-12-31 23:00:00          41.0            1            5.80     0.00   \n",
       "1609 2009-01-01 00:00:00         137.0            1            9.30     0.00   \n",
       "1610 2009-01-01 09:00:00         140.0            1            8.80     0.00   \n",
       "1611 2008-12-31 23:00:00         161.0            1           10.80     0.00   \n",
       "1612 2009-01-01 06:00:00         163.0            1            9.30     0.00   \n",
       "\n",
       "      avg_trip_time  avg_trip_distance  \n",
       "0              11.0               1.33  \n",
       "1              28.0              13.44  \n",
       "2              18.0               1.97  \n",
       "3              40.0               9.53  \n",
       "4              31.0               3.89  \n",
       "...             ...                ...  \n",
       "1608            3.0               0.72  \n",
       "1609            5.0               1.02  \n",
       "1610            9.0               0.64  \n",
       "1611            7.0               1.55  \n",
       "1612            6.0               1.13  \n",
       "\n",
       "[1613 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM  temp_taxi_df\n",
    "    WHERE YEAR(PUDate) < 2011 OR YEAR(PUDate) > 2022\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6d654ac-7485-4d68-8299-742e9d1517a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_taxi_v2 = duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM temp_taxi_df\n",
    "    WHERE YEAR(PUDate) >= 2011 AND YEAR(PUDate) <= 2022\n",
    "\"\"\").df()\n",
    "\n",
    "# type conversion for Tableau (using PULocationID as a key to join the spatial)\n",
    "# turns out PULocationID can't be used as a key to joinning if it's float data type\n",
    "temp_taxi_v2[[\"PULocationID\"]] = temp_taxi_v2[[\"PULocationID\"]].astype(int)\n",
    "temp_taxi_v2.to_csv(os.path.join(\".\", \"data\", \"temp_taxi_v2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0889077c-59b5-469f-a082-f87ed2a8ba54",
   "metadata": {},
   "source": [
    "## Add 0 to Pickup Datetime & PULocation Without Any Ride\n",
    "\n",
    "I exported grouped data which summarizes it beforehand. This is to save storage space. Thus, I need to manually add 0 values to rows with pickup datetime\n",
    "that has no rides at all for each `PULocationID` for more precise hourly analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6d9a1-b501-4b64-9baa-1dad0348a974",
   "metadata": {},
   "source": [
    "Notice the last date data being recorded is Sunday of October, 2022. Let's trim the `final_df` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4a84cac-a190-4a4f-b26f-7c1ebc65438e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUDate</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>total_rides</th>\n",
       "      <th>avg_total_fare</th>\n",
       "      <th>avg_tip</th>\n",
       "      <th>avg_trip_time</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12687855</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>11.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12687856</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>15.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12687857</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>8.76</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12687858</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12687859</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PUDate  PULocationID  total_rides  avg_total_fare  avg_tip  \\\n",
       "12687855 2022-10-01           229            1           11.80     0.00   \n",
       "12687856 2022-10-01           234            1           15.80     2.00   \n",
       "12687857 2022-10-01           237            1            8.76     1.46   \n",
       "12687858 2022-10-01           263            1            9.30     0.00   \n",
       "12687859 2022-10-01             4            1           25.80     0.00   \n",
       "\n",
       "          avg_trip_time  avg_trip_distance  \n",
       "12687855           10.0               1.55  \n",
       "12687856           14.0               1.62  \n",
       "12687857            2.0               0.54  \n",
       "12687858            5.0               1.16  \n",
       "12687859            2.0               0.27  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM temp_taxi_v2\n",
    "    ORDER BY PUDate\n",
    "\"\"\").df().tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3edcfd47-1f3d-4542-8bd4-b0d200cd5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_template = duckdb.query(\"\"\"\n",
    "    SELECT t1.generate_series AS gen_PUDate, t2.generate_series AS PULocationID\n",
    "        FROM generate_series(\n",
    "               (date '2011-01-01')::timestamp,\n",
    "               (date '2022-10-01')::timestamp,\n",
    "               interval '1 hour'\n",
    "               ) AS t1\n",
    "        CROSS JOIN generate_series(1,265,1) AS t2\n",
    "\"\"\").df()\n",
    "\n",
    "taxi_df = duckdb.query(\"\"\"\n",
    "    SELECT gen_PUDate AS PUDate, t1.PULocationID, total_rides, avg_total_fare, avg_tip, avg_trip_time, avg_trip_distance\n",
    "    FROM\n",
    "        (SELECT *\n",
    "        FROM date_template AS t1\n",
    "        LEFT JOIN temp_taxi_v2 AS t2\n",
    "        ON t1.gen_PUDate = t2.PUDate AND\n",
    "           t1.PULocationID = t2.PULocationID) AS t1\n",
    "    ORDER BY gen_PUDate, t1.PULocationID\n",
    "\"\"\").df().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff97e499-6848-439e-95d0-639568c06d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUDate</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>total_rides</th>\n",
       "      <th>avg_total_fare</th>\n",
       "      <th>avg_tip</th>\n",
       "      <th>avg_trip_time</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.189231</td>\n",
       "      <td>0.559744</td>\n",
       "      <td>15.038462</td>\n",
       "      <td>2.919231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PUDate  PULocationID  total_rides  avg_total_fare   avg_tip  \\\n",
       "0 2011-01-01             1          0.0        0.000000  0.000000   \n",
       "1 2011-01-01             2          0.0        0.000000  0.000000   \n",
       "2 2011-01-01             3          0.0        0.000000  0.000000   \n",
       "3 2011-01-01             4         78.0       11.189231  0.559744   \n",
       "4 2011-01-01             5          0.0        0.000000  0.000000   \n",
       "\n",
       "   avg_trip_time  avg_trip_distance  \n",
       "0       0.000000           0.000000  \n",
       "1       0.000000           0.000000  \n",
       "2       0.000000           0.000000  \n",
       "3      15.038462           2.919231  \n",
       "4       0.000000           0.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "201217df-db17-4c11-850c-71cd7d17bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ONCE : Writing a huge data set (1.8GB).\n",
    "# taxi_df.to_csv(os.path.join(\".\", \"data\", \"taxi_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610da75-e955-442b-b061-c6aa3faf675f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7f2f2-8ccd-4ee9-898b-ac00e746f744",
   "metadata": {},
   "source": [
    "# More Efficiently Load Data - Using Dask / S3\n",
    "\n",
    "For the future practice with big datasets, `dask` might be useful.\n",
    "\n",
    "- [How to connect to s3 bucket using `boto3`](https://stackoverflow.com/questions/30249069/listing-contents-of-a-bucket-with-boto3)\n",
    "- [How to set up the credentials for `boto3`](https://www.youtube.com/watch?v=tW3HoYRnABs&ab_channel=KGPTalkie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67120b45-1a59-4e0e-8775-5145feff20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c3a92-4594-4447-849c-3f47dfa069ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "bucket = s3.Bucket(\"nyc-tlc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9446adb-b7ca-430c-a9f6-bdd21bf874dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for obj in bucket.objects.all():\n",
    "    print(obj)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc50d01-36a9-4331-8375-5259c1931355",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_links = list()\n",
    "for link in taxi_links_11_22:\n",
    "    s3_links.append(\"s3://nyc-tlc/trip data/\" + link.split(\"/\")[-1])\n",
    "s3_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b5fcc-b1cf-4d84-87c9-f17635f611de",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a3a80-a9c0-467c-bdff-a43931b0e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp data\n",
    "temp_link = s3_links[0]\n",
    "temp_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711946f-bc9b-40b0-83b9-99f8c4d89210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the rides with trip distance 0 when loading => filtering within partition is possible when using pyarrow engine\n",
    "# https://docs.dask.org/en/stable/generated/dask.dataframe.read_parquet.html\n",
    "filters=[('trip_distance', '>', 1)]\n",
    "\n",
    "# df = dd.read_parquet(s3_links,\n",
    "#                        columns = columns_to_use,\n",
    "#                        filters = filters,\n",
    "#                        engine=\"pyarrow\")\n",
    "\n",
    "# TEMP\n",
    "df = dd.read_parquet(temp_link,\n",
    "                  columns = columns_to_use,\n",
    "                  filters = filters,\n",
    "                  engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817ffbd-b34d-40f6-9c35-824a2db02bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the rows with trip time <= 0\n",
    "df[\"trip_time\"] = (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]).dt.total_seconds() / 60.0\n",
    "df = df[df[\"trip_time\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd01f99-8c88-4d6a-867d-de92c8add14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rides that would require the speed of more than 100 mph.\n",
    "df[\"avg_mph\"] = df[\"trip_distance\"] / (df[\"trip_time\"] / 60.0)\n",
    "df = df[df[\"avg_mph\"] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccbcb8-4cf8-47ed-bf50-97544438cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split `tpep_pickup_datetime` into year, month, and hour\n",
    "df[\"pickup_year\"] = df[\"tpep_pickup_datetime\"].dt.year\n",
    "df[\"pickup_month\"] = df[\"tpep_pickup_datetime\"].dt.month\n",
    "df[\"pickup_wday\"] = df[\"tpep_pickup_datetime\"].dt.weekday\n",
    "df[\"pickup_hour\"] = df[\"tpep_pickup_datetime\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ce835-fa3a-4fdf-847c-11399943f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_df = df.groupby([\"PULocationID\", \"pickup_year\", \"pickup_month\", \"pickup_wday\", \"pickup_hour\"]).agg({\"total_amount\":\"mean\", \"tip_amount\":\"mean\", \"trip_time\":\"mean\"})\n",
    "trend_df[\"count\"] = df.groupby([\"PULocationID\", \"pickup_year\", \"pickup_month\", \"pickup_wday\", \"pickup_hour\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec1ad5-4349-479a-a684-0b6a9df33335",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9156f-a5bf-47e8-b275-4506dccf9666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
